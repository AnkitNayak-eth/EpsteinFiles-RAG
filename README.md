# EpsteinFiles-RAG
A RAG pipeline implementation built on the 'Epstein Files 20K' dataset from Hugging Face (Teyler).

![Recording 2026-02-10 230408](https://github.com/user-attachments/assets/e7378680-b113-442e-b112-7745197ade65)

Dataset source:  
ğŸ‘‰ https://huggingface.co/datasets/teyler/epstein-files-20k

---

## âš¡ Quick Demo

Process 2M+ document lines â†’ Get accurate, grounded answers in seconds

**What it does:**
- Automatically cleans and reconstructs fragmented documents
- Intelligently chunks documents while preserving context
- Embeds everything into a searchable vector database
- Retrieves diverse, relevant information using MMR algorithm
- Generates answers grounded solely in the retrieved context

---

## ğŸ¯ Key Features

âœ… **No Hallucinations** - Answers only from source documents  
âœ… **Intelligent Retrieval** - MMR algorithm for diverse results  
âœ… **Fast Processing** - ~1 second end-to-end query response  
âœ… **Semantic Understanding** - Context-aware document chunking  
âœ… **REST API** - Easy integration with other systems  
âœ… **Interactive UI** - Streamlit web interface included  
âœ… **Scalable** - Handles 100K+ document chunks  
âœ… **Production-Ready** - Async support, error handling, logging  

---

## ğŸ—ï¸ How It Works

### Three Simple Stages

**Stage 1: Data Preparation**
```
Raw Documents (2.5M lines)
    â†“
Clean & Reconstruct
    â†“
Smart Chunking
    â†“
Vector Embeddings
```

**Stage 2: Intelligent Retrieval**
```
User Question
    â†“
Find Similar Context (MMR)
    â†“
Return Top Chunks
```

**Stage 3: Grounded Answer**
```
Context + Question
    â†“
LLaMA 3.3 LLM
    â†“
Grounded Answer (with sources)
```

### Why MMR Instead of Similarity?

**Previous Approach:** Pure semantic similarity  
â†’ Returned redundant chunks from same document

**Current Approach:** Maximal Marginal Relevance (MMR)  
â†’ Balances relevance + diversity for comprehensive context

---

## ğŸ“¦ Installation

### Requirements
- Python 3.11+
- 16GB RAM (8GB minimum)
- Groq API key (free at [console.groq.com](https://console.groq.com))

### Setup (5 minutes)

**1. Clone repository**
```bash
git clone https://github.com/AnkitNayak-eth/EpsteinFiles-RAG.git
cd EpsteinFiles-RAG
```

**2. Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

**3. Install dependencies**
```bash
pip install -r requirements.txt
```

**4. Configure environment**

Create `.env` file:
```
GROQ_API_KEY=your_api_key_here
```

## ğŸš€ Getting Started

### Run Complete Pipeline (First Time)

This processes data and prepares the system for queries:

```bash
# Stage 1: Download raw data (~5-15 min)
python ingest/download_dataset.py

# Stage 2: Clean and reconstruct documents (~3-8 min)
python ingest/clean_dataset.py

# Stage 3: Create semantic chunks (~5-12 min)
python ingest/chunk_dataset.py

# Stage 4: Generate embeddings (~20-45 min)
python ingest/embed_chunks.py
```

### Start Using the System

**Terminal 1 - Start API Server**
```bash
uvicorn api.main:app --reload
```
API runs at: `http://127.0.0.1:8000`

**Terminal 2 - Start Web UI**
```bash
streamlit run app.py
```
UI opens at: `http://localhost:8501`

**That's it!** You can now query through the web interface or API.

---
## ğŸ“š Project Structure

```
EpsteinFiles-RAG/
â”œâ”€â”€ ingest/                    # Data processing pipeline
â”‚   â”œâ”€â”€ download_dataset.py    # Download from Hugging Face
â”‚   â”œâ”€â”€ clean_dataset.py       # Clean & reconstruct docs
â”‚   â”œâ”€â”€ chunk_dataset.py       # Semantic chunking
â”‚   â””â”€â”€ embed_chunks.py        # Embed & index
â”œâ”€â”€ api/                       # FastAPI backend
â”‚   â”œâ”€â”€ main.py               # API routes
â”‚   â””â”€â”€ models.py             # Data models
â”œâ”€â”€ app.py                     # Streamlit UI
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env.example              # Environment template
â””â”€â”€ README.md                 # This file
```

---

## ğŸ“œ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Dataset:** [Teyler/Epstein Files 20K](https://huggingface.co/datasets/teyler/epstein-files-20k) on Hugging Face
- **Embeddings:** [Sentence Transformers](https://www.sbert.net/)
- **Vector DB:** [Chroma](https://www.trychroma.com/)
- **LLM Inference:** [Groq Cloud](https://console.groq.com/)
- **Framework:** [LangChain](https://www.langchain.com/)
- **UI:** [Streamlit](https://streamlit.io/)

---

## ğŸ“ Support

**Built by:** Ankit Kumar Nayak  
**Full-Stack Developer | AI & RAG Systems**

**Get Help:**
- ğŸ“ [Open an Issue](https://github.com/AnkitNayak-eth/EpsteinFiles-RAG/issues)
- ğŸ’¬ [Start a Discussion](https://github.com/AnkitNayak-eth/EpsteinFiles-RAG/discussions)

---

## âš ï¸ Disclaimer

This project is built for **research, transparency, and educational purposes**. All data is sourced from public records. Users are responsible for complying with applicable laws and ethical guidelines when using this system.

---
